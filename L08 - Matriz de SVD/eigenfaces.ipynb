{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74909acd",
   "metadata": {},
   "source": [
    "## Eigenfaces\n",
    "\n",
    "Eigenfaces (en español caras propias) es el nombre dado a un conjunto de autovectores cuando se utiliza en el problema de visión artificial del reconocimiento de rostros humanos. Matthew Turk y Alex Pentland lo propusieron en su [paper en la clasificación de caras](https://doi.org/10.1162/jocn.1991.3.1.71).\n",
    "\n",
    "Aquí se muestra como hacer el cálculo del Análisis en Componentes Principales para los datos de los rostros, y luego aplicarlos para la reducción del espacio. Con este nuevo espacio se realizan dos tareas: reconstrucción y clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0337c",
   "metadata": {},
   "source": [
    "Definición de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_reducida(A,k='max',tol=1e-12):\n",
    "    # A completar por ustedes!\n",
    "\n",
    "def splitDataset(data, label):\n",
    "    # split dataset en entrenamiento y test\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for train, test in skf.split(data.T, label.T):\n",
    "        break\n",
    "    train_data = data[:,train]\n",
    "    train_lab = label[:,train]\n",
    "    test_data = data[:,test]\n",
    "    test_lab = label[:,test]\n",
    "    \n",
    "    return train_data, train_lab, test_data, test_lab\n",
    "\n",
    "def showPic(data, idx, dx=38):\n",
    "    # graficamos una rotro\n",
    "    v = data[:,idx] # primera columna\n",
    "    m = v.reshape((dx,dx)).T\n",
    "    plt.imshow(m, cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f47f7",
   "metadata": {},
   "source": [
    "La lectura del archivo de datos nos devuelve dos matrices, una correspondiente a las imágenes de los rostros y la otra a un label que indica a cual\n",
    "persona pertenece la imágen.\n",
    "\n",
    "<img src=\"image_vector.png\" />\n",
    "\n",
    "Como vemos en la figura, las imágenes se convirtieron a vector, con $N=38$ para este set de datos y por lo tanto tenemos $n = N^2 =1444$ variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('base_40_38_10.mat')\n",
    "# data es una matriz de 1444 x 380.\n",
    "# Corresponde a figuras de caras de tamanio 38x38 pixeles\n",
    "data = mat['data']\n",
    "label = mat['label']\n",
    "# extraemos la dimensionalidad de data, donde n es la cantidad de ejemplos, y d la dimensión del espacio.\n",
    "d, n = data.shape\n",
    "\n",
    "showPic(data, 51)\n",
    "\n",
    "print(label.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fedfdd",
   "metadata": {},
   "source": [
    "## Análisis de Componentes Principales (ACP o PCA en inglés)\n",
    "\n",
    "Vamos a hacer una modificación respecto del formalismo que usamos en la sección precedente, ya que vamos a acomodar las muestras (los rostros) como columnas.\n",
    "Tampoco vamos a dividir por el desvío estándar ya que las imágenes están acotadas en sus valores de niveles de gris de los pixeles (y por lo tanto están en la misma escala).\n",
    "\n",
    "\n",
    "Primero centramos los valores de las imágenes, restando la media.\n",
    "Luego calculamos la matriz de covarianzas:\n",
    "\n",
    "\n",
    "$C = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu) (x_i - \\mu)^{T}$\n",
    "\n",
    "Finalmente encontramos los autovalores y autovectores de esta matriz, los cuales ordenamos de mayor a menor valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculoACP(data):\n",
    "    dx = 38\n",
    "    d, n = data.shape\n",
    "    m=np.mean(data, axis=1)\n",
    "    print(m)\n",
    "    plt.imshow(m.reshape((dx,dx)).T, cmap=plt.cm.gray)\n",
    "    \n",
    "    X = data - np.tile(m.reshape((len(m), 1)), (1, n))\n",
    "    Mcov = np.dot(X,X.T) / n # Covariance Matrix\n",
    "\n",
    "    U, D, V = svd_reducida(A)# Completen con su implementación de SVD\n",
    "    \n",
    "    # ordenamos los autovalores de mayor a menor\n",
    "    idx = np.argsort (- D )\n",
    "    D = D[idx]\n",
    "    U = U[:, idx]\n",
    "\n",
    "    return D, U, X, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2098f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, U, data_ref, m = calculoACP(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695e750",
   "metadata": {},
   "source": [
    "Veamos como se ven las imágenes que quedan representadas en las columnas de U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "showPic(U, 0)\n",
    "print(U[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9626994",
   "metadata": {},
   "source": [
    "El espacio de proyección del ACP esta compuesto por el vector V que es de tamaño $n \\times n$.\n",
    "\n",
    "El próximo paso busca la reducción del espacio de proyección, para quedarnos con aquellos autovectores en V que acumulen la mayor cantidad de información posible en las distintas direcciones.\n",
    "\n",
    "Para ello se hace un cómputo de la varianza acumulada en el vector D, y se selecciona una cantidad que signifique representar un 95 % de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.cumsum(D) / np.sum(D)\n",
    "plt.plot(ratio)\n",
    "x = np.where(ratio > 0.95)[0]\n",
    "M = x[0]\n",
    "\n",
    "print('Cantidad de autovectores de representación al 95 %: ', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7a050",
   "metadata": {},
   "source": [
    "### Reconstrucción de un rostro\n",
    "\n",
    "El hecho que quedarse con menos autovectores para la proyección del espacio, conlleva a una reducción de almacenamiento de la información, pero al mismo tiempo a cometer un error al tratar de reconstruir la imagen original.\n",
    "\n",
    "En este tramo de código representamos visualmente la imagen original y la reconstruida con M autovectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d481a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruccion\n",
    "idx_im = 5\n",
    "im_orig = data_ref[:,idx_im]\n",
    "cpM = U[:,0:M].T @ im_orig \n",
    "\n",
    "print(cpM.shape)\n",
    "\n",
    "im_rec = U[:,0:M] @ cpM \n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].imshow(im_orig.reshape((38,38)).T, cmap=plt.cm.gray)\n",
    "axes[1].imshow(im_rec.reshape((38,38)).T + m.reshape((38,38)).T, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446c67a",
   "metadata": {},
   "source": [
    "## Clasificación de nuevas imágenes\n",
    "\n",
    "La tarea de clasificación en predecir a quien de las personas de la base de conocimientos pertenece un rostro de testing. Esto lo vamos a realizar gracias a proyectar el rostro de entrada al espacio de ACP y calcular por distancias, cual es rostro más cercano.\n",
    "\n",
    "En primer lugar separamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93026b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clasificacion\n",
    "train_data, train_lab, test_data, test_lab = splitDataset(data, label)\n",
    "Dt, Ut, train_ref, m = calculoACP(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35e78d",
   "metadata": {},
   "source": [
    "Luego elegimos la cantidad de componentes que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea55c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.cumsum(Dt) / np.sum(Dt)\n",
    "plt.plot(ratio)\n",
    "x = np.where(ratio > 0.95)[0]\n",
    "M = x[0]\n",
    "print('Cantidad de autovectores de representación al 95 % de la base de entrenamiento: ', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba76e7",
   "metadata": {},
   "source": [
    "Y por último elegimos la etiqueta en base a la proyección de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf = train_ref.T @ Ut[:,0:M]   # proyectamos a la base de entrenamiento, de los cuales conocemos a que persona pertenece\n",
    "\n",
    "input_test = test_data[:,0] # vamos a clasificar el primer sujeto de la base de test\n",
    "test_acp = (input_test - m) @ Ut[:,0:M]    # le resto la media y proyecto en el espacio reducido de Vt\n",
    "Q = np.tile(test_acp.reshape((1,-1)), (data_clf.shape[0], 1))  \n",
    "dist = np.linalg.norm(data_clf - Q, axis=1)    # calculo las distancias a cada una de las imágenes de conocimientos proyectadas en el espacio ACP.\n",
    "y = np.argmin(dist)                             # clasificar por el más cercano\n",
    "\n",
    "if test_lab[0][0] == train_lab[0][y]:\n",
    "    print('Clasificacion correcta')\n",
    "else:\n",
    "    print('clasificacion incorrecta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb2a99",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Ejecutar el script anterior pero evaluando el error de clasificaciones correctas e incorrectas para todo el test_data.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
